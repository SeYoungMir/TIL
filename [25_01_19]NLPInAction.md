# 2. 더 깊은 학습: 신경망 적용
## 5. 신경망 첫걸음: 퍼셉트론과 역전파
### 1. 신경망의 구성 요소
#### 3. 치우침 단위
##### 퍼셉트론의 훈련
- 앞의 발판이 곧 학습의 출발점. 학습 과정에서 서로 다른 여러 견본이 신경망 시스템에 입력, 그럴 때마다 뉴런의 출력이 정답인지 아닌지에 기초, 가중치들이 조금씩 갱신. 견본이 충분히 많다면(끄리고 그 밖의 여러 조건이 적절하다면)출력의 오차가 점차 0으로 수렴. 오차가 0이 되면(또는 0에 충분히 가까우면) 시스템은 학습을 마친 것.
- 이 과정의(그리고 신경망 학습 전체의)핵심은 각 가중치를 해당 특징이 오차에 기여하는 정도에 근거해서 갱신한다는 것. 큰 특징은 내적에 더 큰 영향을 미치며, 따라서 만일 오차가 크게 나왔다면 작은 특징보다 큰 특징의 책임이 더 큼.
- 앞의 example_input 견본에 대해 뉴런이 0을 출력해야한다고 가정할 때, 다음은 그에 맞게 가중치를 갱신하는 코드
- ```python
  expected_output = 0
  new_weights = []
  for i, x in enumerate(exampe_input):
    new_weights.append(weights[i]+(expected_output-perceptron_output)*x)
  weights = np.array(new_weights)
  example_weights
  weights
  ```
- 위 과정을 다른 여러 입력 견본과 정답의 쌍들로 반복하면 퍼셉트론은 이전에 본 적이 없는 입력에 대해서도 정확한 결과를 예측(다른 여러 조건이 적절할 때)
