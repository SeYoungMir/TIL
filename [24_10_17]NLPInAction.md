# 1.NLP 기초.
## 3. TF-IDF 벡터
- 2장에서 문장에서 단어(토큰)들을 추출해 빈도를 세고 분류하는 방법, 비슷한 토큰들을 어간이나 표제어로 통합하는 방법을 학습
- 토큰들로 중요도를 측정하는 방법을 학습, 단어 용례에 관한 통계량을 얻거나 단순한 키워드 검색을 수행하는 데는 토큰화만으로도 충분, 더 본격적인 응용을 위해서는 주어진 단어가 특정 문서에서 또는 말뭉치 전체에서 얼마나 중요한지 측정할 수 있어야 함.
- 이러한 단어의 '중요도'는 검색 엔진에서 사용자가 입력한 검색어들과 관련성이 깊은 문서를 찾는 데 도움이 됨. 단어의 중요도는 스팸 검출기가 비속어 하나나 스팸성 단어 몇 개 때문에 주어진 이메일을 스팸으로 오판하지 않게 하는 데에도 도움이 됨
- '긍정성' 점수 또는 분류명이 부여된 다양한 단어들을 갖추고 잇다면, 한 트윗이 얼마나 긍정적이고 사교적인지 측정 가능, 더 나아가서 한 문서에서 그런 단어들이 등장한 횟수를 나머지 모든 문서의 해당 빈도와 비교해서 주어진 문서의 '긍정성'점수를 측정 가능.
- 단어들과 문서 안에서의 단어의 용도에 관한 좀 더 미묘한, 덜 이분법적인 측도를 탐색. 이번에 소개하는 접근 방식은 수십 년간 상용 검색 엔진들과 스팸 필터들이 자연서 텍스트에서 특징(feature)들을 추출하는 주된 수단으로 사용.
- 다음 NLP 학습 단계는 앞의 단어들을 그냥 단어 출현 횟수를 나타내는 정수나 특정 단어의 존재 여부를 나타내는 이진 '비트 벡터' 형태로만 표현하는 것이 아니라 주어진 응용에 의미가 있는 연속된 값으로 변환하는 것.
- 이번 장에서는 단어들을 이산 공간이 아니라 연속 공간에서 표현. 단어들을 연속 공간에서 표현하면 좀 더 다양한 수학 도구들로 단어 표현들을 다룰 수 있음.
- 목표는 단어의 중요도 또는 단어의 정보 내용을 반영한 수치 표현을 탐색.
- 단어의 중요도를 반영하는 수치 표현에 초점. 단어의 의미를 수량화 하는 방법은 다음 장에서 이야기
- 이번 장의 세 가지 단어 중요도 표현 방법을 탐색.
  - 단어 모음 - 단어 빈도(출현 횟수)들의 벡터
  - n - 그램 모음 - 2-그램(두 단어 쌍), 3-그램(세 단어 쌍)등의 빈도들의 벡터
  - TF-IDF 벡터 - 단어의 중요도를 좀 더 잘 표현하는 단어 점수 벡터.
    - TF-IDF는 term frequency times inverse document frequency, 즉 용어 빈도에 역문서 빈도를 곱한 값. 용어 빈도는 한 문서 안에 단어가 출현한 횟수, 역문서 빈도는 단어의 빈도를 그 단어가 출현한 문서의 개수로 나눈 것.
- 이 기법들은 그 자체로 따로 적용 가능, NLP 파이프라인의 일부로서 적용도 가능.
- 빈도(도수)에 기초한다는 점에서 이들 모두 통계적 모형. 단어 관계와 패턴, 비선형성을 좀 더 깊게 파악하는 고급 응용 표현은 이후에 소개.
- 이런 '얕은' NLP 모형도 스팸 필터링이나 감정 분석 같은 실용적인 응용 프로그램에 사용하기에 강력,유용