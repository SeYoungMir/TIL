# 2. 더 깊은 학습: 신경망 적용
## 6. 단어 벡터를 이용한 추론: word2vec 활용
### 2. 단어 벡터
#### 2. word2vec의 단어 표현 계산
- 부정 표집.
  - 미콜로프가 고안한 마지막 개선 요령은 부정표집(negative sampling;음성 표집)을 적용하는 것. 목표 단어와 주변 단어들로 이루어진 하나의 훈련 견본을 신경망에 입력하면 신경망의 모든 가중치가 갱신. 그러면 어휘의 모든 단어에 대한 단어 벡터의 성분들이 변함.
  - 그런데 어휘의 단어수가 수십, 수백만 규모이면 커다란 원핫 벡터에 대해 모든 가중치를 갱신하는 데 시간이 오래 걸림. 단어 벡터 모형의 훈련 속도를 높이기 위해 미콜로프는 부정 표집 기법을 사용
  - 미콜로프는 문맥 구간에 포함되지 않은 단어들까지 포함한 모든 단어의 가중치들을 갱신하는 대신, 예측 결과가 '부정(negative; 음성)'인 단어들만 가중치 갱신에 사용한다는 착안을 제시. 즉, 출력 벡터에 기초해서 부정 견본(기대 출력과는 다른 출력이 나온 견본)n개를 뽑고(그래서 '부정 표집')해당 출력들에 기여한 가중치들을 갱신. 이렇게 하면 훈련된 신경망의 정확도가 크게 떨어지지 않으면서도 훈련에 필요한 계산량이 극적으로 감소
    - 단어 벡터 모형을 작은 말뭉치로 훈련할때는 부정 표집률을 표본당 5에서 20견본으로 두는 것이 바람직. 그리고 말뭉치와 어휘가 클 때는 부정 표집률을 2에서 5 정도로까지 낮추어도 됨.