# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 1. 단어 빈도에서 주제 점수로
#### 2. 주제 벡터
- TF-IDF 벡터들을 더하거나 빼서 얻은 합이나 차는 그 벡터들이 나타내는 문서의 단어 빈도에 관한 정보만 제공, 그 단어들에 담긴 의미에 관해서는 아무것도 말해 주지 않음.
- TF-IDF 행렬에 그 자신을 곱하면 단어 대 단어의 상관관계를 나타내는(즉, 특정 단어들이 함께 나타나는 비율을 말해 주는)TF-IDF 벡터들을 획득. 그러나 이런 희소 고차원 벡터들로는 문서의 의미를 추론하기 어려움. 이런 벡터들을 더하고 뺀다 해도 단어의 개념이나 주제를 잘 표현하는 결과가 나오지는 않음.
- 따라서 우리에게는 단어 통계량들로부터 추가적인 정보, 즉 의미에 관한 정보를 추출하는 또 다른 방법이 필요. 특히, 문서의 의미를 잘 나타내는 단어들을 추출 가능해야 함.
- 더 나아가, 문서의 의미를 잘 나타내는 단어들의 조합까지도 식별 가능해야함. 그리고 그런 정보를 벡터 형태로 표현 가능해야 하며, TF-IDF 벡터보다 더 간결하고 의미 있는 형태의 벡터여야 좋음.
- 단어의 의미를 표현하는 그러한 간결한 벡터를 '단어-주제 벡터(word-topic vector)' 라고 부르고, 문서의 의미를 표현하는 벡터를 '문서 - 주제 벡터'라고 부름. 그리고 그 둘을 통칭해서 '주제 벡터' 라고 부름. 이하의 논의에서, 주어진 주제 벡터가 단어에 대한 것인지 아니면 문서에 대한 것인지를 문맥에서 명확히 구분할 수 있거나 굳이 구분할 필요가 없을 때는 그냥 '주제 벡터'라고 표기.
- 이런 주제 벡터들의 차원 수(성분 개수)는 응용에 따라 다름. LSA(잠재 의미 분석)에서 주제 벡터는 1차원일 수도 있고 수천차원일 수도 있음.
- 이 주제 벡터들도 기본적으로는 선형대수에서 말하는 벡터이므로 얼마든지 더하거나 뺄 수 있음. 단, 이러한 주제 벡터 덧셈이나 뺄셈은 이전 장의 TF-IDF 벡터들을 더하고 빼는 것보다 훨씬 의미가 큰 결과를 냄.
- 그리고 두 주제 벡터의 거리는 문서 군집화(Clustering)나 의미 기반 검색 같은 응용에 유용. 이전 장에서는 문서들을 키워드나 TF-IDF 벡터를 이용해서 묶거나 검색, 이제는 의미, 즉 뜻을 이용해서 묶거나 검색.
- 말뭉치에 대한 주제 벡터 계산을 완료하면 말뭉치의 문서 당 하나씩의 문서- 주제 벡터와 어휘의 단어당 하나씩의 단어- 주제 벡터가 생성.
- 여기서 중요한 점은, 말뭉치에 새로운 문서를 추가했을 때, 그 문서의 문서-주제 벡터를 계산하기 위해 말뭉치 전체를 다시 계산할 필요가 없음. 한 문서의 문서-주제 벡터는 그 문서들에 쓰인 단어들의 단어-주제 벡터들을 결합, 새 문서가 기존 어휘에는 없는 단어들만 사용하는 것이 아니라면 기존 단어-주제 벡터들로 문서의 주제 벡터를 계산.
  - 단 잠재 디리클레 할당 등의 몇몇 주제 벡터 생성 알고리즘은 새 문서 추가시마다 말뭉치 전체를 다시 처리.