# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 5. 잠재 디리클레 할당(LDiA)
#### 1. LDiA의 기초
- 이전의 통계량은 반드시 BOW 들에서 직접 계산해야함에 주의
- 문서들을 토큰화하고 벡터화한(Counter()를 적용한) 단어들의 수를 세어야 함. 또한, 먼저 불용어 필터링이나 기타 정규화를 적용한 후에 고유한 단어들의 수를 세어야 한다는 점도 명심. 즉, 문서에 실제로 쓰인 단어 중 불용어들을 제외한 단어들의 종류를 세어야 함. 예제의 LDiA 알고리즘은 이번 장의 다른 알고리즘들처럼 단어 모음 벡터 공간 모형을 가정.
- 2번 수치, 즉 주제의 수는 좀 더 까다로움. 특정 문서 집합의 주제 수는 실제로 단어들을 주제들에 배정해보기 전까지는 정확히 측정할 수 없음 이는 $k$-평균 군집화나 $k$-최근접 이웃(KNN)군집화 같은 군집화 알고리즘들처럼 먼저 $k$를 결정해야 다음 단계로 나아갈 수 있는 것과 비슷한 상황. 이런 딜레마를 극복하는 한 가지 방법은 주제 개수($k$-평균 군집화의 군집 개수 $k$에 해당하는)를 잠정적으로 결정, 알고리즘을 수행한 후 그 결과를 보고 주제 개수를 좀 더 조율해 나가는 것. 어쨌든, 일단 주제 개수를 지정해 주면, LDiA는 각 주제에 대해 목적 함수가 최적값이 되는 단어들의 혼합을 찾아냄.
- 이 $k$(주제 수)처럼 알고리즘의 작동 방식과 다른 매개 변수들의 계산에 영향을 미치는매개변수를 '초매개변수(hyperparameter)'라고 부름. LDiA를 반복하면서 이 $k$값을 조율하다 보면 최고의 성과가 ㅏ오는 $k$값에 도달. 물론 이러한 최적화 과정을 자동화하는 것도 가능, 그러러면 LDiA 언어 모형의 품질을 평가하는 방법이 필요. 즉 ,LDiA의 결과가 말뭉치에 있는 문서들의 의미를 얼마나 잘 나타내는지 측정할 수 있어야 함. 한 가지 방법은 LDiA 모형을 어떤 분류 또는 회귀 문제에 적용, 그 결과와 정답의 오차를 측정하는 것. 기계 학습의 어법으로 말하면 이는 모형의 '비용 함수(cost function)'를 평가하는 것에 해당. 이전에 논의한 감정 분석이 그러한 분류/회귀 문제에 속하며, 문서의 키워드 태깅이나 주제 분석도 분류/회귀 문제에 속함. 정답으로서의 분류명(감정,키워드,주제 등)이 붙은 문서들로 LDiA모형(주제 모형 또는 분류기)을 실행해서 오차를 측정.