# 2. 더 깊은 학습: 신경망 적용
## 5. 신경망 첫걸음: 퍼셉트론과 역전파
### 1. 신경망의 구성 요소
#### 6. 흔들어서 탈출
- 좀 더 흔히 쓰이는 방법은 미니배치(mini-batch;작은 일괄 단위)를 사용하는 것. 미니 배치 훈련 방식에서는 훈련 집합 전체 또는 앞에서 말한 배치를 더 작은 부분 집합들로 나눔. 각각의 작은 부분집합이 바로 미니배치. 한 미니배치에 대해 순전파와 역전파를 수행, 가중치를 갱신하는 과정을 모든 미니배치에 대해 반복해서 하나의 훈련 주기를 마침. 이 방법은 배치 훈련의 장점인 속도와 확률적 경사 하강법의 장점인 안정성(극소점 극복)을 모두 갖춤.
- 역전파의 세부적인 작동 방식이 매혹적, 이해하기가 쉽지는 않음. 앞에서 언급했듯이 역전파의 세부 사항은 이 책의 범위를 넘는 주제. 신경망은 오차 곡면의 경사로를 최대한 빨리 내려가서 바닥에 닿는 방법. 
#### 7. 케라스: 신경망 파이썬 구현
- 순수한 파이썬으로 신경망을 직접 구현해 보면 지금까지 배운 것을 머릿속에서 정리하는 데 도움이 될 뿐만 아니라 재미있을 것임. 그러나 파이썬은 다른 몇몇 언어에 비해 속도가 그리 빠르지 않고 신경망의 계산량이 상당히 크기 때문에, 순수한 파이썬 구현으로는 적당한 크기의 신경망이라도 감당하기 어려울 정도로 처리 시간이 길 수 있음 .다행히 PyTorch나 Theano, TensorFlow, Lasague처럼 파이썬의 느린 속도를 극복할 수 있는 기계 학습 라이브러리가 많이 있으며, 여기서는 케라스(Keras([링크](http://keras.io)))를 사용
- 케라스는 사용하기 쉬운 파이썬 API를 제공하는 고수준 신경망 래퍼(wrapper). 케라스는 서로 다른 기계 학습 패키지인 Theano,TensorFlow(구글),CNTK(마이크로소프트)를 거의 동일한 방식으로 사용할 수 있는 API를 제공. 이 세 가지 뒷단(backend)는 각각 기본적인 신경망 구성요소들의 저수준 구현과 내적과 행렬 곱셈을 비롯한 여러 신경망 관련 수학 연산을 아주 빠르게 수행하는 고도로 조율된 선형대수 라이브러리를 갖춤.