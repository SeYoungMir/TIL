## 분류: 나이브베이즈(Naïve Bayes)
### Keywords
- 조건부 확률
- 베이즈 정리
### 나이브베이즈
- 지도학습 알고리즘
- 분류 알고리즘
- 특성변수가 주어졌을 때, Y 범주의 확률 계산에 베이즈 정리를 이용
- 생성 모델(generative model)
### 나이브베이즈(Naïve Bayes) 분류기
- 나이브 베이즈 분류기 아이디어
  - 목표 변수 $Y$가 2개의 범주 $C_1,C_2$를 가진다고 할 때, 특성변수 $X$의 값을 이용하여 $Y$의 범주를 예측하는 문제.
  - $X=x$로 주어졌을 때 $Y$의 각 범주에 대한 조건부 확률을 비교하고자 함.
  - $P[C_1|x]>P[C_2|x]$면 $C_1$으로 분류하고, 그렇지 않으면 $C_2$으로 분류함
  - $P[C_k|x]$는 훈련 자료에서 추정하기 어려움$\rArr$베이즈 정리를 이용.
  - 나이브 베이즈 분류기는 생성(generative)모델임.
- 베이즈 정리의 활용
  - 베이즈 정리에 의하면,<br>$P[C_k|x]={P[x\cap C_k]\over P[x]}={P[x|C_k]P[C_k]\over P[x]}, k=1,2$
  - $P[C_1|x]>P[C_2|x]$인지 여부.<br>$\rArr{P[x|C_1]P[C_1]\over P[x]}>{P[x|C_2]P[C_2]\over P[x]}$인지 여부<br>$\rArr P[x|C_1]P[C_1]>P[x|C_2]P[C_2]$인지 여부로 판단하고자 함.
  - $P[x|C_k]$와 $P[C_k]$는 훈련 데이터를 이용하여 쉽게 추정할 수 있음.
- $n$개의 특성변수를 가지는 분류 문제
  - $P[C_k|x_1,...,x_n]$에 베이즈 정리를 적용.<br>$P[C_k|x_1,...,x_n]={{P[C_k]}P[x_1|C_k]P[x_2|x)1,C_k]...P[x_n|x_1,...,x_{n-1},C_k]\over {P[x_1,...,x_n]}},k=1,2$
  - 각 특성변수들이 모두 독립이라고 가정하면,<br> $P[C_k]P[x_1|C_k]P[x_2|x)1,C_k]...P[x_n|x_1,...,x_{n-1},C_k]=P[C_k]P[x_1|C_k]P[x_2|C_k]...P[x_n|C_k]=P[x|C_k](\Pi_{i=1}^nP[x_i|C_k]),k=1,2$
  - 예측<br>$P[x|C_1](\Pi_{i=1}^nP[x_i|C_1])\geq P[x|C_2](\Pi_{i=1}^nP[x_i|C_2])$면 범주 1로 분류.<br>$P[x|C_1](\Pi_{i=1}^nP[x_i|C_1])< P[x|C_2](\Pi_{i=1}^nP[x_i|C_2])$면 범주 2로 분류.
    - $P[C_k]$
      - $k$번째 범주에 속할 확률
    - $P[x_i|C_k]$
      - 목표변수가 $k$번째 범주일 때, 각 특성변수 $x_i$가 관찰될 확률
      - $x_i$의 자료형식(범주형/개수형/연속형)에 따라 적절한 확률분포를 가정하여 추정.
    - Original data > Estimation of First dimension > Estimation of Second dimension > Resulting data distribution
- 나이브 베이즈의 장단점
  - 장점
    - 데이터의 크기가 커도 연산 속도가 빠름 
    - 학습에 필요한 데이터 양이 적어도 좋은 성능을 보이는 편
    - 다양한 텍스트 분류나 추천 등에 활용됨
  - 단점
    - Zero frequency 문제나 Underflow 문제가 있음.
    - 모든 독립변수가 독립이라는 가정이 너무 단순함.
