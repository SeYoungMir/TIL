# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 2. 잠재 의미 분석(LSA)
#### 1. 처리 예시
- 앞에서 간단히 예시로 든 주제들을 LSA 알고리즘으로 처리.
- LSA 알고리즘에게 우리가 원하는 주제들을 산출하라고 지시하는 방법은 없지만, 시도해보고 어떤일이 벌어지는 지 살펴보면 흥미로움.
- 짧은 문서들로 이루어진 작은 말뭉치라면 단 몇 개의 차원(주제)들로도 문서의 의미를 포착 가능
- ```python
  from nlpia.book.examples.ch04_catdog_lsa_3x6x16 import word_topic_vectors
  word_topic_vectors.T.round(1)
  ```
- 위 예시가 출력한 주제 - 단어 행렬의 각 행은 '단어-주제 벡터'
- 이 벡터는 주어진 주제에 각 단어가 얼마나 관련이 있는지 표현. 이 벡터를 구성하는 단어 - 주제 점수들은 감정 분석 모형에서 사용한 단어 긍정성 점수들과 유사. 기계 학습 파이프라인에서 단어의 의미를 표현하는 데 쓰이는 것이 이 단어-주제 벡터.
- 이 벡터를 '의미 벡터(semantic vector)'라고도 부르기도 함. 이 단어- 주제 벡터들을 합치면 문서에 대한 주제 벡터.
- 사고 실험처럼 SVD도 세 주제를 제시. 첫 주제(topic0)은 "apple" 과 "NYC" 에 큰 가중치를 부여했다는 점에서 이전의 'cityness' 주제와 유사. 단, 이전에 우리는 'cityness' 주제를 세 번째로 두었지만 LSA 는 첫 번째로 두었음.
- 이는 LSA가 주제들을 그 중요도 순으로, 즉 자료 집합에서 각 주제가 얼마나 많은 정보 또는 분산을 대표하는지 순서로 정렬하기 때문. 예에서 자료 집합의 최대 분산 축에 해당하는 차원이 topic0이며, 말뭉치를 살펴보면 "NYC" 와 "apple"이 있는 문장들도 많고 두 단어가 아예 없는 문장들도 많기 때문에 분산이 제일 크게 나오기 때문.
- topic1은 앞서 예시로 가정한 주제와는 좀 다름. "love"에 대한 점수가 월등히 크다는 점에서 LSA는 "animalness"보다 "love"가 문서들의 본질적인 의미를 더 잘 반영한 주제라고 판단.
- topic2는 "dog"의 점수가 월등히 크고 "love"도 조금이나마 기여했으므로 '애견' 주제로 불러도 될 것.
- "cat"은 topic0의 점수가 -0.6이며 , LSA는 "cat"이 이 주제와 상반된 단어로 간주. 이는 "cat"과 "NYC"가 동시에 나오는 ㅁ누장이 별로 없기 때문.
- LSA가 단어들의 의미를 실제로 이해하지 않고서도 이런 주제 벡터들을 생성하는 방법을 이해하기 위해 다음 예시를 참고.