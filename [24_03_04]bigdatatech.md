# 5. 크롤러 설계/개발(응용)
## 5. 병렬 처리
### 3. 작업 큐(여러 개의 머신을 사용, 병렬 처리) - 이어서
6. task_routes 설정에 대해
   - task_routes 설정을 보면, Celery를 사용 태스크 라우팅.
   - 라우팅이란 어떤 워커에 어떤 태스크를 실행시킬지 지정
   - 예제에서는 download 큐와 media 큐를 각각의 태스크에 연결.
   - 라우팅 없이 워커 프로세스를 2개로 하고, 동시에 2개씩 내려받도록 했을때는 내려받기 태스크가 2개 실행되고 있는 동안에는 워커가 다른 작업을 실행할 수 없음.
   - 따라서 cut_mp3 함수의 경우, 2개의 내려받기 태스크 중 어느 한 쪽이 끝나서 워커가 비어야만 실행.
   - cut_mp3 함수는 네트워크 처리에 걸리는 시간과 상대 서버에 대한 부담과관계가 없기 때문에, 곧바로 처리해도 괜찮으므로, 워커를 역할별로 2개 실행 가정, 코드 작성
7. 워커 실행
   - 워커는 애플리케이션 실행 전에 해야함
   - 주의점. Pydub은 내부적으로 FFmpeg 명령어를 서브 프로세스로 실행. media 전용 워커 프로세스를 백그라운드 실행하고 있는 상태에서는 서브 프로세스 호출 불가
   - 다음과 같은 방식으로 워커 실행 시 내려받기 작업은 정상적으로 종료되지만 mp3 데이터 수정태스크가 진행되지 않음
    ```
    $ celery -A crawler_with_celery_sample worker -Q download -c 2 -l info -n download@%h &
    $ celery -A crawler_with_celery_sample worker -Q media -c 2 -l info -n media@%h &
    ```
    - celery 명령어 뒤에 -A 옵션으로 Celery를 사용해서 실행할 대상 애플리케이션을 지정, worker 옵션은 워커 실행을 의미, -Q 옵션은 사용되는 큐의 이름 의미. -c 옵션은 생성할 워커의 수 의미
    - -l 옵션은 Celery 로그 출력 레벨. 직접 만든 애플리케이션의 logger에 설정한 로그 수준과 다르게 지정 가능. -n 옵션은 워커 이름 지정
8. 크롤러 실행
    ```
    $ python crawler_with_celery_sample.py
    ```
    - 로그 몇 개 출력 후 프로그램 끝나는 것처럼 보여도, 조금 기다리면 워커의 처리에 의해 로그 계속 출력
    - 위 실행 결과는 [download finished] 05Anim.mp3에서 중단. 따라서 [ctrl]+ [C]키로 프로그램 중단.
    - 폴아웃 명령어 fg로 실행한 워커도 마찬가지로 종료
    - 의도하지 않은 태스크가 큐잉(Queueing) 되면 예상하지 못한 문제 발생.
9. 큐 비우기
   - 의도하지 않은 태스크 큐잉 시 다음 명령어로 큐 비우기
    ```
    $ celery -A crawler_with_celery_sample purge
    ```
    