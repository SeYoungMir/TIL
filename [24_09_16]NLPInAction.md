# 1.NLP 기초.
## 2. 단어 토큰화
### 2. 토큰 생성기를 이용한 어휘 구축 - 이어서
- 기본적인 키워드 검색이 목적이라면 원핫 단어 벡터와 이진 단어 모음 벡터를 비트별 논리합(bitwise-OR)으로 결합할 수도 있음.
- 그러면 검색어로 그리 유용하지 않은 수많은 단어를 생략할 수 있게 됨.
- 이런 접근 방식은 검색 엔진의 색인화 작업이나 정보 검색 시스템의 1차 필터에는 적합. 검색을 위한 색인에는 각 단어가 주어진 문서에 존재하는지의 여부(1또는0)만 있으면 됨.
- 순서 없이 단어를 한 데 모으는 것은 그다지 좋은 문장 생성 방법은 아니지만, 컴퓨터가 단어들의 집합을 하나의 단위로 '이해'하게 만드는 데는 꼭 필요. 가장 중요한 단어 10,000개로 어휘 제한 시 앞에서 예로 든 가상의 3,500문장 서적 한 권을 약 10KB의 단어 모음 자료 구조로 압축 가능, 3000권에는 약 30MB로 압축. 원핫 벡터 테이블이라면 수백 GB가 필요.
- 하나의 문서에 쓰이는 단어의 수는 어휘 크기에 비하면 작고, 대부분의 단어 모음 응용에서는 문서를 짧게 유지. 경우에 따라서는 문장 하나 단위로도 좋은 결과를 얻을 수 있음. 따라서 단어 모음 벡터는 피아노의 건반 전체를 두드리는 것이라기 보다는 듣기 좋은 화음을 연주하는 것에 더 가깝고, 서로 잘 어울리거나 의미상으로 연관이 있는 단어들을 집합을 표현. 챗봇은 '불협화음'에 해당하는 음, 즉 주어진 문장의 다른 단어들과 함께 쓰이는 경우가 드문 단어들이 좀 있어도 그런 화음을 잘 처리할 수 있음. 기계학습은 불협화음에 해당하는 드문 단어 조차도 문장에 관한 유용한 정보를 추출하는데 활용할 수 있음.
- 주어진 문장의 토큰화를 거친 단어들로 특정 단어의 존재 여부를 나타내는 이진 벡터를 구축하는 법을 살펴보자.
- 이진 벡터는 어떤 단어가 어떤 문서에 쓰였는지를 말해주는 문서 검색 색인에 유용. 이색인은 교과서 끝에 있는 색인(찾아보기)와 유사. 단 특정 단어가 몇 쪽에 나왔는지 말해 주는 것이 아니라 어떤 문장 또는 문서에 나왔는지를 말해줌.
- 교과서의 찾아보기는 중요한 용어들만 나열, 단어 모음 이진 벡터는 문서의 모든 단어를 포함.
- 다음은 토머스 제퍼슨 문장을 이진 단어 모음 벡터로 압축하는 예.
- ```python
  >>>sentence_bow={}
  >>>for token in sentence.split():
  ...    sentence_bow[token]=1
  >>>sorted(sentence_bow.items())
  ```
- 압축 결과에서 한 가지 눈에 뜨는 것은 파이썬의 sorted()가 숫자를 영문자보다 먼저 나오고 대문자가 소문자보다 먼저 나오도록 항목들을 정렬한다는 것. 이는 ASCII 문자 집합과 유니코드 문자 집의 정렬 순서. 사실 어휘의 단어 순서는 중요하지 않으며, 모든 문서에 대해 같은 순서를 사용하는 한, 어떤 순서라도 기계 학습 파이프라인이 잘 작동함.