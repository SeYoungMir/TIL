# 4. 빅데이터 적재 I - 대용량 로그 파일 적재
## 2. 빅데이터 적재에 활용하는 기술
### 1. 하둡
- 하둡 소개
  - 빅데이터의 핵심 소프트웨어
  - 빅데이터의 에코시스템들은 대부분 하둡을 위해 존재하고 하둡에 의존해서 발전해 가고 있다 해도 될 정도
  - 하둡의 두 가지 기능
    - 대용량 데이터를 분산 저장하는 것
    - 분산 저장된 데이터를 가공/분석 처리하는 기능
  - 하둡은 두번째 기능인 데이터 가공/분석을 위해 분산 병령 처리 기술을 사용, 분산 컴퓨팅 기술은 하둡이 처음 개발되기 시작한 2005년 이전부터 이미 사용되었지만, 높은 투자비용으로 특정 분야에서만 활용중이었음.
  - 구글에서 2003년, 2004년 논문 발표하면서 구글의 검색 엔진 기술 공개, 논문 기반으로 2005년에 하둡의 창시자인 더그 커팅이 넛치/루씬(Nutch/Lucene) 검색엔진의 서브 프로젝트로 하둡 프로젝트를 추진하면서 분산 컴퓨팅 기술의 저변 확대 시작
  - 2006년에 아파치 최상위 프로젝트로 독립되어 비약적인 발전 거듭, 2013년 10월에는 하둡 2.0 정식 버전이 릴리즈, 한층 더 강력한 빅데이터 기술로 자리매김함
- 하둡의 맵리듀스
  - 분산 병령 처리의 핵심은 여러 컴퓨터에 분산 저장되어있는 데이터로부터 어떻게 효율적으로 일을 나눠서(Map)실행시킬 수 있는가
  - 다음으로 여러 컴퓨터가 나눠서 실행한 결과들을 어떻게 하나로 모으는가(Reduce)
  - 이를 쉽고 편리하게 지원하는 프레임워크가 하둡의 맵 리듀스(MapReduce)
  - 맵리듀스는 분산 컴퓨팅 기술을 이해하는 중요한 열쇠.
    - 기본 구조 예시
      - 고객 정보가 담긴 1GB의 파일을 100MB 파일 10개로 나눠 10대의 서버(하둡 데이터 노드)에 분산 저장(나눠진 100MB 파일을 블록 파일이라 부르며 일반적으로 128MB 블록 단위로 처리)
      - 전체 고객 정보에서 VIP 고객의 평균연봉 조회 쿼리를 실행, 10대의 서버에 분산 저장된 100MB의 고객정보 파일로부터 Map 프로그램이 각각 생성
      - 실행된 Map 프로그램은 100MB의 고객정보 파일에서 VIP 고객 정보만 추출, 작아진 파일(2~8MB) 크기로 Server-11(Reduce)로 전송
      - Server-11에서 Reduce 프로그램이 실행되어 Server-01(Map 01) ~ Server-10(Map10)이 전송한 VIP 고객 정보를 머지(50MB)해 평균을 구하고 결과 파일(1KB)을 해석
    - 위의 구조는 대용량 데이터에 대한 처리를 여러 대의 서버들이 나누어 작업함으로써 한 대의 고성능 서버가 처리하기 힘든 작업을 신속하게 처리
    - 실제 MapReduce가 동작할 때는 한 대의 서버에 여러 개의 블록 파일이 저장되기도 하며, 여러개의 Map/Reduce가 한 서버에서 동시 다발적으로 실행되기도 함
    - 각 Map/Reduce가 실행되는 중에 중간 파일을 만들어 로컬 디스크에 임시 저장해 처리가 완료된 파일은 다음 작업 서버로 전송
    - MapReduce 프로그램에서는 내부적으로 Split,Spill,Sort,Partition,Fetch,Shuffle,Merge 등 다양한 메커니즘들이 작동, 이 과정을 잘 이해하고있어야 분산 환경에서 발생하는 다양한 문제에 빠르게 대처할 수 있음