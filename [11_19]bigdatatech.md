# 3. 빅데이터 수집
## 3. 수집 파일럿 실행 1단계 - 수집 아키텍처
### 1. 수집 요구사항
- 앞의 빅데이터 파일럿 프로젝트의 두 가지 요구사항을 살펴보고, 빅데이터 수집 관점에서 요구 사항을 더 구체화, 해결하기 위한 솔루션과 기술 요소들을 도출
- 요구사항 1 : 차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검
- 요구사항 2 : 운전자의 운행 정보가 담긴 로그를 실시간으로 수집, 주행 패턴 분석
### 2. 요구사항 구체화 및 분석
- 파일럿 프로젝트의 수집 요구사항 분석
<table>
    <tr>
        <th>수집 요구사항 구체화</th>
        <th>분석 및 해결 방안</th>
    </tr>
    <tr>
        <td>1. 스마트카로부터 로그 파일들이 주기적으로 발생함</td>
        <td>플럼을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집</td>
    </tr>
    <tr>
        <td>2. 스마트카의 배치 로그 파일 이벤트를 감지해야 함</td>
        <td>플럼의 Source 컴포넌트 중 SpoolDir를 이용해 주기적인 로그 파일 발생 이벤트를 감지</td>
    </tr>
    <tr>
        <td>3. 스마트카의 실시간 로그 발생 이벤트를 감지해야 함</td>
        <td>플럼의 Source 컴포넌트 중 Exec-Tail을 이용해 특정 로그 파일에서 로그 생성 이벤트를 감지</td>
    </tr>
    <tr>
        <td>4. 스마트카가 만들어내는 로그데이터에 가비지 데이터가 있을 수 있음</td>
        <td>플럼의 Interceptor를 이용해 정상 패턴의 데이터만 필터링</td>
    </tr>
    <tr>
        <td>5. 수집 도중 장애가 발생해도 데이터를 안전하게 보관 및 재처리할 수 있어야 함</td>
        <td>플럼의 메모리 Channel 및 카프카 Broker 사용으로 로컬 디스크의 파일 시스템에 수집 데이터를 임시 저장</td>
    </tr>
    <tr>
        <td>6. 스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리를 해야 함</td>
        <td>플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송</td>
    </tr>
</table>

### 3. 수집 아키텍처
- 위 표의 수집 요구사항 참조, 스마트카의 빅데이터 분석을 위한 파일럿 프로젝트의 수집 아키텍처 구성
- 스마트카 로그 시뮬레잍터
  - 운전자 운행 정보 > 1초 간격 발생, 400KB/1초 > 실시간 수집 > 플럼 에이전트 1 
    - SpoolDir Source > Memory Channel > Logger Sink
    - 플럼 Stdout
      - Log 파일
  - 차량 상태 정보 > 3초 간격 발생, 100MB/1일 > 일 단위 수집 > 플럼 에이전트 2
    - ExecTail Source> Memeory Channel > Kafka Sink 
    - 카프카
      - Topic
- 파일럿 프로젝트의 수집 아키텍처는 원천 데이터의 발생 유형에 따라 크게 2개의 레이어로 나뉨
  - 대용량 로그 파일을 주기적으로 수집해서 표준 입출력 로거로 보여주는 플럼 에이전트 1 레이어
  - 실시간 발생 로그를 라인 단위로 수집, 카프카의 Topic에 전송하는 플럼 에이전트 2 레이어
### 4. 로그 시뮬레이터
- 스마트카의 상태 정보와 운전자의 운행 정보 로그를 가상으로 만드는 자바 로그 발생기
  - 1. 스마트카 상태 정보 : 100대 스마트카 장치들의 상태 정보를 3초 간격으로 바랭시키며, 1일 100MB의 로그 파일이 만들어짐
  - 6. 스마트카 운전자 운행 정보: 100명의 스마트카 운전자들의 운행 정보를 실시간으로 발생시키며, 발생된 하나의 운행 정보 로그는 4KB 미만, 동시에 최대 400KB 용량으로 실시간 데이터 발생
### 5. 플럼 에이전트 1
- 스마트카 상태 정보를 기록한 로그 파일을 일별로 수집하기 위한 배치성 플럼 에이전트
  - 2. SpoolDir Source : 약속된 로그 발생 디렉터리를 모니터링하다가 정의된 로그 파일 발생 시 해당 파일의 내영을 읽어서 수집하는 기능 재공
  - 3. Memory Channel : SpoolDir Source로부터 수집된 데이터를 메모리 Channel 에 중간 적재. 버퍼링 기능을 제공, Sink와 연결되어 트랜잭션 처리를 지원
  - 4. Logger Sink : Channel로부터 읽어들인 데이터를 플럼의 표준 로그 파일로 출력하게 됨
### 6. 플럼 에이전트 2
- 스마트카 운전자의 운행 정보를 실시간으로 수집하기 위한 실시간성 플럼 에이전트
  - 7. Exec-Tail Source : 로그가 쌓이고 있는 파일에 Tail 파이프라인을 이용해 실시간으로 데이터를 수집하는 기능 제공
  - 8. Memory Channel : Exec-Tail Source로부터 수집된 데이터를 메모리 Channel 에 버퍼링 처리를 하면서 임시 적재
  - 9. Kafka Sink : Channel로부터 읽어들인 데이터를 카프카 Broker의 특정 토픽에 비동기 방식으로 저송하는 Provider 역할을 수행
### 7. 기타
- 플럼이 수집한 로그 데이터를 임시 출력 및 저장
  - 5. Flume Stdout : 플럼의 Logger-Sink를 통해 표준 출력 로그가 출력됨
  - 10. Kakfa Topic : 플럼의 Kafka-Sink는 수집된 실시간 로그를 임시 적재함
## 4. 수집 파일럿 실행 2단계 - 수집 환경 구성
- 플럼 설치
- 카프카 설치
## 5. 수집 파일럿 실행 3단계 - 플럼 수집 기능 구현
- 2개의 에이전트 구현, 스마트카 상태 정보 수집 에이전트, 운전자 운행 정보 수집 에이전트
- SmartCar 에이전트 생성
- SmartCar 에이전트에 Interceptor 추가
- DriverCarInfo 에이전트 생성
## 6. 수집 파일럿 실행 4단계 - 카프카 기능 구현
- 직접적 기능 구현 X, 명령어를 통해 카프카의 브로커 안에 토픽을 생성, Producer 명령어를 통해 토픽에 데이터를 전송, 토픽에 들어간 데이터를 카프카의 Consumer 명령어로 수신
- 카프카 Topic 생성
- 카프카 Producer 사용
- 카프카 Consumer 사용

## 7. 수집 파일럿 실행 5단계 - 수집 기능 테스트
- 지금까지 구성한 빅데이터 수집 기능이 정상적으로 작동하는지 테스트를 통한 점검
- SmartCar 로그 시뮬레이터 작동
- 플럼 에이전트 작동
- 카프카 Consumer 작동
- 수집 기능 점검