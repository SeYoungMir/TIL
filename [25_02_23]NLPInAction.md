# 2. 더 깊은 학습: 신경망 적용
## 6. 단어 벡터를 이용한 추론: word2vec 활용
### 2. 단어 벡터
#### 2. word2vec의 단어 표현 계산
##### 스킵그램 접근 방식
- 스킵그램 접근 방식에서는 주어진 입력 단어에 기초해서 일정 범위 이내의 주변 단어들을 예측하도록 모형을 훈련. 
- 클로드 모네에 관한 다음 같은 문장에서 "painted" 주변 단어를 예측하려면 신경망은 "Claude","Monet","the","Grand"라는 주변 단어 스킵그램을 출력
  - ``` Claude Monet painted the Grand Canal of venis in 1908'
- 주변 단어 (surrounding word)들을 예측하는 신경망의 구조는 앞에서 배운 기본적인 신경망의 구조와 비슷함. 스킵그램을 위한 신경망의 구조는 입력층, 은닉층, 출력층으로 이루어진 다층 신경망, 은닉층은 n개의 뉴런으로 구성됨. 여기서 n은 단어 하나를 표현하는 벡터의 차원 수. 입력층과 출력층은 각각 M개의 뉴런으로 구성, 여기서 M은 모형의 어휘 크기(단어 개수). 출력층의 활성화함수는 분류 문제에 흔히 쓰이는 소프트맥스 함수
##### 소프트맥스 함수
- 소프트맥스 함수는 분류 문제의 해법을 배우는 것이 목표인 신경망의 출력층 활성화 함수로 자주 쓰임. 소프트맥스는 임의의 범위의 입력을 0에서 1 사이의 출력값으로 "압축"
- 그리고 한 출력층의 모든 소프트맥스 출력의 합은 항상 1. 따라서 출력층의 한 소프트맥스의 출력을 확률로 취급.
- 출력층을 구성하는 K개의 노드 각각에 대해, 소프트맥스 출력값은 다음과 같이 정규화된 지수 함수로 정의
  - $\sigma(z)_j={{e^{zj}}\over{\Sigma^K_{k=1}e^{zk}}}$
- 출력층의 뉴런인 경우, 세 뉴런의 출력을 하나의 3차원 열벡터로 표현 가능.
- 원본 출력 벡터를 소프트맥스 활성화 함수를 이용해서 '압착'
- 세 성분의 합이 약 1.0으로 하나의 확률분포로 구성.
