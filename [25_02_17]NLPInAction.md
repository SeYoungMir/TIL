# 2. 더 깊은 학습: 신경망 적용
## 6. 단어 벡터를 이용한 추론: word2vec 활용
### 2. 단어 벡터
- 비지도학습에서는 사람의 '지도' 또는 도움 없이 모형이 자료로부터 직접 학습. 훈련 자료를 따로 사람이 조직화,구조화하고 분류명을 붙일 필요가 없음 .따라서, 분류되지 않은 비구조적 자료가 훨씬 더 많은 자연어 처리 분야에는 word2vec같은 비지도 학습 알고리즘이 제격.
- 비지도 학습에서는 분류명 없는 원본 자료로 직접 모형을 훈련. k-means나 DBSCAN같은 군집화 알고리즘이 비지도 학습의 예. 그리고 주성분 분석(PCA)나 t-분포 확률적 이웃 내장(t-Distributed Stochastic Neighbor Embedding,SNE)도 비지도 학습에 해당. 비지도 학습에서 모형은 자료점들 사이의 관계들에 존재하는 패턴을 스스로 찾아냄. 비지도 학습 모형은 그냥 더 많은 자료를 투입하기만 해도 정확도가 높아짐
- word2vec에서 신경망 훈련의 목표는 신경망이 대상 단어의 의미를 직접 배우는 것이 아니라 문장 안에서 대상 단어 근처의 단어들을 예측하게 만드는 것. 이 경우 예측하고자 하는 이웃 단어들이 바람직한 출력, 즉 분류명에 해당. 그러나 그런 분류명들은 사람이 미리 지정해둔 것이 아니라 모형이 자료 집합 자체에서 가져온 것이므로, word2vec 알고리즘은 비지도 학습에 속함.
- 비지도 학습 기법이 유용하게 쓰이는 또 다른 분야는 시계열(time series)모형화. 시계열 모형은 주어진 시계열(순차열)의 일정 구간이 이전 값들에 기초해서 그 다음 값을 예측하도록 훈련될 때가 많음. 시계열 예측 문제는 여러 면에서 자연어 처리 문제와 상당히 비슷한데, 이는 둘 다 어떤 값(단어와 수치)들의 순차열(순서 있는 배열)을 다루기 때문.
- word2vec에서 그러한 이웃 단어의 예측 자체가 중요한 것은 아님. 예측은 단지 목적을 위한 한 수단. 중요한 것은 모형의 내부 표현, 즉 예측을 위해 word2vec이 점진적으로 형성해 나가는 벡터들. 이 표현은 대상 단어의 의미를 잠재 의미 분석(LSA)과 잠재 디리클레 할당(LDiA)이 산출하는 단어-주제 벡터보다 더 많이 포착.