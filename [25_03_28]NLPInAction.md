# 2. 더 깊은 학습: 신경망 적용
## 6. 단어 벡터를 이용한 추론: word2vec 활용
### 2. 단어 벡터
#### 8. 단어 관계의 시각화.
- 이러한 "증강된" 도시 벡터를 이미 NLPIA 패키지에 저장. 그냥 바로 적재해서 사용하면 됨.다음은 증강된 도시 단어 벡터들을 PCA를 이용해서 2차원으로 투영하는 코드
- ```python
  from sklearn.decomposition import PCA
  pca = PCA(n_components=2)
  us_300D =get_data('cities_us_wordvectors')
  us_2D = pca.fit_transform(us_300D.iloc[:,:300])
  ```
- 다음은 300차원의 미국 도시 단어 벡터들을 2차원으로 투영한 모습
- ![alt text](image-16.png)
- 두 단어의 의미 거리가 짧다(0에 가깝다)는 것은 두 단어가 아주 비슷하다는 뜻. 두 단어의 의미 거리(semantic distance 또는 meaning distance)는 훈련에 쓰인 문서들에서 해당 두 단어가 문맥 구간 안에 함께 출현한 횟수에 의존. 두 단어가 같은 문장의 문맥 구간 안에 출현한 횟수가 많을수록 word2vec 단어 벡터 공간에서 두 단어의 벡터들이 가까이 놓임.
- 두 용어의 단어 벡터가 멀다는 것은 두 단어가 같은 문맥을 공유할 가능성이 작다는, 따라서 의미가 비슷할 가능성이 작다는 의미.
- 위의 지도를 재현해보고 싶거나, 자신의 말뭉치로 이런 지도를 직접 만들어보고 싶다면 다음 코드를 참고. NLPIA 패키지의 plots 는 Ploty의 오프라인 그래프 작성 API를 감싼 모듈. 이 모듈의 함수들을 이용하면 DataFrame에 담긴 자료로 손쉽게 그래프를 작성할 수 있음. 이 함수들은 각 행이 하나의 견본(자료점)이고 각 열이 견본의 각 특징(성분)인 DataFrame을 요구. 각 특징은 범주형 특징(도시 자료의 경우 시간대) 일수도 있고 수치형 특징(인구수) 일수도 있음. 이 함수들은 다양한 종류의 기계 학습 자료를 탐색하는 데 융요한 상호작용적인 그래프 생성 .특히 단어나 문서 같은 복잡한 대상의 벡터 표현에 유용.