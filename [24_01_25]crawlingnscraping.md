# 2. 크롤러 설계
## 2. 크롤러가 가지는 각각의 처리를 설계할 때 주의 사항
### 5. 데이터 저장소의 구조와 선택
2. 데이터베이스
   - 내려받은 페이지 또는 파일이 어떤 인덱스 페이지의 파일인지, 요청 시에 응답 헤더가 어땠는지 등의 세부적인 부가 정보를 함께 기록하고 싶을 땐느 일반적으로 MySQL 등의 관계형 데이터베이스를 사용
   - 예를 들면 MySQL 데이터베이스에는 바이너리 데이터를 저장할 수 있는 BLOB 형식의 칼럼 존재. 이에 내려받은 파일의 내용을 저장하면 디렉터리를 구분해서 데이터를 저장할 필요가 없음
   - 파일의 내용을 KVS, 문서형 DB, 객체 스토리지로 구분해서 저장할 때도 키를 MySQL에 저장하면 관리 편해짐
3. 데이터가 있는지 확인
   - 크롤링을 할 때는 같은 URL을 크롤링하는 경우가 발생 가능. 같은 URL을 매번 요청한 뒤 데이터를 다시 저장하는 것은 굉장히 비효율적인 일.
   - 이미 수집한 URL은 특별한 경우가 아니라면 다시 요청하지 않아도 됨
   - 수집한 URL을 데이터베이스에 저장하고, 다음번에 수집할 때 URL이 데이터베이스에 있는지 확인하면 좋음
   - URL이 너무 길 때도 있고, 인덱스의 문자 길이 제한 등에 걸리는 경우도 있으므로, URL과 함께 URL 해시(SHA-1 등)을 저장하고, 이를 이용해 존재 여부를 확인하면 좋음

## 3. 배치를 만들 때의 주의점
### 1. 배치란?
- 배치(Batch Program)란 정해진 일련의 처리를 한 번에 하는 프로그램을 의미, 크롤러도 특정 페이지에 접근하고, 필요한 데이터를 추출, 이를 저장하는 일련의 흐름을 처리하는 배치
1. 공정 분리하기
   - 네트워크 요청과 스크레이핑 부분은 다른 함수 또는 클래스로 만들 수 있음.
   - 분리 가능한 경우가 이상적
   - 추가로 목록 페이지에서 상세 페이지로 들어가고 상세 페이지를 스크레이핑 하는 경우, 목록 페이지에사 상세 페이지 URL 추출부분과 상세 페이지 스크레이핑 처리 분리하는 것이 좋음
   - 네트워크 요청 처리와 스크레이핑 처리가 함께 있으면 스크레이핑에 실패할 경우 네트워크 요청 처리부터 해야하므로, 서버에 부하 발생, 전체적인 효율 나빠짐
   - 세세하게 요청과 스크레이핑을 분류 시 연결 흐름이 잘 보이지 않아 유지 보수가 어려워질 수 있음.
   - 따라서 모든 처리가 동시에 이뤄지는 설계는 피하면서 균형 있을 정도로 분리 필요
