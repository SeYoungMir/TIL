## 3. 적재 파일럿 실행 1단계 - 적재 아키텍처
### 1. 적재 요구사항
- 요구사항 구체화 및 분석
  <table>
    <tr>
        <td>적재 요구사항 구체화</td>
        <td>분석 및 해결 방안</td>
    </tr>
    <tr>
        <td>1. 100대에 달하는 스마트카들의 상태 정보가 일 단위로 취합되어 제공됨</td>
        <td>플럼에서 수집 발생 시점의 날짜를 HdfsSink에 전달해서 해당 날짜 단위로 적재</td>
    </tr>
    <tr>
        <td>2. 매일 100대의 스마트카 상태 정보는 약 100MB 정도이며, 220만건의 상태 정보 발생</td>
        <td>1년 적재 시 8억건 이상의 데이터가 적재되며, 연 단위 분석에 하둡의 분산 병렬 처리 사용</td>
    </tr>
    <tr>
        <td>3. 스마트카의 상태 정보 데이터의 발생일과 수집/적재되는 날짜가 다를 수 있음</td>
        <td>수집/적재되는 모든 데이터마다 데이터 발생일 외에 수집/적재 처리되어야 하는 처리일을 추가</td>
    </tr>
    <tr>
        <td>4. 적재된 스마트카들의 상태 정보를 일·월·년 단위로 분석 가능 해야함</td>
        <td>HDFS에 수집 일자별로 디렉터리 경로를 만들어서 적재</td>
    </tr>
    <tr>
        <td>5. 적재 및 생성되는 파일은 HDFS의 특성을 잘 고려해야함</td>
        <td>플럼의 HdfsSink의 옵션을 파일럿 프로젝트의 HDFS에 최적화해서 설정</td>
    </tr>
    <tr>
        <td>6. 적재가 완료된 후에는 원천 파일이 삭제되어야 함</td>
        <td>플럼의 Source 컴포넌트 중 SpoolDir의 DeletePolicy 옵션을 활용</td>
    </tr>
  </table>
- 적재 아키텍처
  - 위의 표는 대용량 로그 파일을 적재하기 위한 요건. 아키텍처는 다음처럼 구성
    - 데이터 
      - 차량 상태 정보 100MB/1일
    - 플럼 에이전트 1
      - SpoolDir Source
      - Memory Channel
      - HDFS Sink
    - 하둡
      - NameNode
      - DataNode 1,2,3
        - HDFS
          - 경로
            - 일별/주별/월별/년별 분석
        - 맵& 리듀스
  - 플럼의 Source 컴포너느로 대용량 파일을 읽어들이고 Sink를 이용햐 HDFS의 특정 경로에 적재하는 구성
  - HDFS에 적재할 때는 데이터의 포맷, 경로, 파티션 값을 신중하게 설정해야 함.
    - 데이터 적재 정책에 따라 뒤에서 탐색/분석을 위한 후처리 작업량과 복잡도 달라질 수 있기 때문
    - 부분 수정/삭제가 어렵기 때문에 유형에 따라 특별한 관리 정책이 필요
      - 시계열 형식의 트랜잭션(거래,이력등) 데이터는 일자별 파티션 폴더를 구성, 파티션 단위로 데이터를 적재 및 수정
      - 마스터(고객정보, 상품 정보 등)데이터는 상대적으로 크기가 작아 전체 데이터셋을 교체하는 방식 
      - 데이터 관리 정책을 통해 초기 적재 레이어에는 원천을 그대로 유지하며 데이터 레이크라 불리는 영역을 구성
        - 이후 데이터 가공작업으로 데이터의 품질을 높이며 빅데이터 웨어하우스와 마트 구성