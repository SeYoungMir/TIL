# 1.NLP 기초.
## 1. 사고의 단위: NLP 개요
### 4. 컴퓨터 입장으로 언어 읽기 
#### 4. 다른 접근 방식 - 이어서
- 메시지의 모든 다어를 세는 과정에서 손실된 정보에 대해서 생각할 필요가 있음.
- 앞에서 말한 과정에서 각 단어들을 각각의 통 또는 '슬롯'에 배정하는 과정에서 단어 분류 결과는 일종의 하나의 비트 벡터로 저장됨.
- 우리의 분류 기계는 화자 또는 저자가 사용할 수 있는 모든 가능한 단어에 대응되는 수천 수만의 일종의 '동전 액면가'를 고려해야 함.
- 이 분류기를 통과한 각각의 문구나 문장, 문서는 결국 각 슬롯의 토큰 개수를 성분으로 하는 하나의 '벡터'가 되는데, 대부분의 성분은 값이 0임. 심지어 장황한 어휘로 된 긴 문서도 그럼.
- 벡터는 어떤 단어가 몇 번이나 출현 했는지를 말해줄 뿐, 문장의 의미를 말해주지는 않음. 단어들의 순서에 대한 정보 없이 단지 출현 횟수만 가지고 긴 문서의  의미를 이해하기란 아주 어렵거나 사실상 불가능. 단, 아주 짧은 문장이라면 단어들을 재배치해서 원래 문장을 복원할 수도 있음.
- 불용어(stopword; 정지 단어)필터와 '드문' 단어 필터가 동전 분류기처럼 작동, 이런 필터에서는 주어진 문자열을 집어넣으면 바닥의 토큰 '스택'들의 높이에 따라 단어 모음(bag-of-word;또는 단어 주머니)벡터들이 만들어짐.
- 컴퓨터는 이런 단어 모음 벡터를 상당히 잘 처리할 수 있으며, 꽤 긴 문서에 담긴 정보도 대부분 이런 식을 ㅗ뽑아 낼 수 있음. 핵심은, 토큰 분류 및 집계(counting)을 통해서 한 문서를 하나의 단어 모음 벡터, 즉 그 문서에 담긴 단어 또는 토큰들의 출현 횟수로 이루어진 하나의 정수(integer) 벡터로 표현할 수 있다는 것임.
- 이상이 자연어에 대한 첫 번째 벡터 공간 모형. 하나의 문서는 모든 가능한 단어에 대응되는 각각의 분류통(bin)에 담긴 단어 개수들로 이루어진 긴 벡터로 표현, 그 벡터의 성분들은 대부분 0이고, 실제로 문서에 존재하는 상대적으로 소수의 단어에 대해서만 0이 아님. 그리고 모든 가능한 단어 조합에 해당하는 벡터들은 하나의 벡터 공간(vector space)을 형성. 더 중요한 것은 이 공간에 있는 벡터들 사이의 관계가 자연어 모형을 형성한다는 점.
- 이 모형은 다양한 단어열들의 한 집합(어떤 문장이나 문서)안에서 특정 단어 조합을 예측하는 데 쓰임.
- 파이썬에서는 이러한 희소 벡터(대부분의 성분이 0인 벡터)를 사전(dictionary) 자료 구조로 표현 가능. 그리고 파이썬의 Counter는 '토큰'(문자열의 단어)들을 각각의 통으로 분류, 그 개수를 세는 기능을 제공.