# 2. 더 깊은 학습: 신경망 적용
## 6. 단어 벡터를 이용한 추론: word2vec 활용
- NLP의 최근 발전 중 가장 흥미로운 것은 단어 벡터(word vector)의 '발견'. 이번 장은 단어 벡터가 무엇이고 어떻게 사용하는지 살펴봄. 다소 의외의 일을 할 수 있을 정도로 단어 벡터가 강력한 수단임을 알게 됨.
- 특히 이전 장들의 근사(축소)기법때문에 사라졌던 단어의 희미하고 미묘한 의미를 어느 정도 복구하는 방법을 학습
- 이전 장들에서는 단어 주변의 문맥을 그냥 무시, 즉 주어진 단어의 앞과 뒤에 있는 단어들은 고려하지 않음. 우리는 한 단어의 이웃들이 그 단어의 의미에 미치는 영향과 그런 관계들이 문장의 전체 의미에 미치는 영향을 무시. 단어 모음(bag-of-words)이라는 자료 구조는 그냥 한 문서의 단어들을 통계적'자루(bag;또는 가방)'에 뒤죽박죽 집어넣은 것.
- 이번 장에서는 문서나 문장의 모든 단어가 아니라 한 단어의 '이웃'단어 몇 개 만으로 작은 단어 모음을 만듦. 이 떄, 그런 단어 모음이 문장들의 경계를 넘지는 않게 함. 즉, 인접한 두 문장의 단어들로 하나의 단어 모음을 만들지는 않음. 이렇게 하면 단어 벡터 훈련 과정이 문서 전체가 아니라 서로 관련된 단어들에 집중.
- 이런 식으로 만들어낸 새로운 단어 벡터를 이용하면 동의어나 반의어를 식별할 수 있으며, 더 나아가서 같은 범주에 속한 단어들도 식별 가능. 물론 제 4장에서 배운 잠재 의미 분석(LSA)으로도 그런 일을 할 수 있지만, 한 단어의 이웃 범위를 좀 더 좁히면 단어 벡터의 정확도가 좀 더 높아짐. 단어나 n-그램, 문서에 대한 잠재 의미 분석은 한 단어의 명시적인 의미 중 일부를 놓칠 수 있으며, 함축된 또는 숨겨진 의미는 더욱 많이 놓칠 위험이 있음. LSA의 단어 모음('자루')은 너무 크기 때문에, 한 단어의 몇몇 의미가 도대체 어디에 틀어 박혀있는지 찾기 어려울 수 있음.