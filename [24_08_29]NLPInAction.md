# 1.NLP 기초.
## 1. 사고의 단위: NLP 개요
### 4. 컴퓨터 입장으로 언어 읽기 
#### 5. 벡터 차원 축소
- 이후 3장에서는 단어들을 결합해서 벡터 차원을 축소해서 차원의 저주를 완화(혹은 경우에 따라서 그것을 유익하게 활용하는)방법을 논의.
- 벡터 투영(projection)을 이용하면 두 벡터 사이 각도의 코사인 값을 손쉽게 계산 가능, 그 값은 두 벡터가 표현하는 문장들의 의미(meaning)가 어느 정도나 비슷핱지를 나타낸다는 점에서 단순한 단어 사용 빈도보다 유용함.
- 이러한 벡터 거리 측도를 코사인 거리함수(cosine distance metric)이라고 함. 
- 이후 장에서는 축소된 차원 주제 벡터에 대한 코사인 거리함수의 진정한 위력을 접하며, 이 벡터들을 2차원 평면에 투영한그래프를 사람이 눈으로 보고 어떤 패턴을 찾을 수도 있음.
- 실제로 어떤 패턴이 존재한다면, 컴퓨터에게 그런 패턴을 식별하고 그에 따라 반응하게 함으로써 컴퓨터가 해당 벡터들의 근원이 된 단어들의 바탕 의미에 맞게 행동하게 만들 수도 있음.
- 사람이 쓸 수 있는 모든 가능한 트윗이나 메시지, 문장을 상상한다면 아무리 많은 문장을 쓴다고 해도 여전히 다른 가능한 문장이 만이 남아 있고. 모든 종류의 토큰을 각자 개별적인, 서로 구별되는 차원(성분)들로 취급한다면 영어 인사말과 독일어 인사말이 실제로 비슷한 의미를 공유한다는 점을 파악하는 것은 불가능.
- 이 문제를 극복하려면 단어들을 결합해서 차원들을 줄인 벡터, 즉 축소 차원 벡터(reduced dimension vector)로 메시지를 표현해야 함.
- 한 가지 방법은 주어진 문장이나 단어들에 대화의 주제나 정서 같은 '성질(quality)'에 관한 어떤 평가치를 부여하는 것.
- 이를테면 문장에 대해 다음과 같은 질문을 던질 수 있음.
  - 이 메시지가 질문일 가능성은 어느 정도?
  - 이것이 사람에 관한 문장일 가능성은?
  - 이것이 나에 관한 메시지일 가능성은?
  - 이 문장의 화자의 감정 표현은 어떨까?
  - 내가 대답해야 할 메시지인가?
- 이 외에도 다양한 '평가치(rating)'를 문장에 매길 수 있음. 그리고 그런 모든 평가치로 또 다른 '벡터'를 형성한다면, 그러한 벡터는 모든 가능한 개별 토큰에 해당하는 성분들로 이루어진 단어 모음 벡터보다는 차원 수(성분 개수)가 훨씬 낮을 것임. 이것이 바로 축소 차원 벡터 표현.
- 이러한 표현에서 중요한 것은, 두 문장의 축소 차원 벡터가 비슷하다는 것은 여러 질문에 대한 평가치가 비슷하다는 뜻이며, 따라서 두 문장은 실제로 그 의미나 정서가 비슷할 것이라는 점임.