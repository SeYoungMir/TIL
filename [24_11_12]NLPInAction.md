# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 1. 단어 빈도에서 주제 점수로
#### 3. TF-IDF 벡터 주제 벡터 변환 원리
- 앞에서 각 주제에 대한 여섯 단어의 가중합으로 이루어진 벡터는 6차원 벡터. 즉 우리는 세 개의 6차원 문서 주제 벡터를 획득, 이는 하나의 자연어 문서에 대해 사람이 손수 가중치를 결정해 얻은 하나의 3주제 모형에 해당.
- 그 어떤 문서이든 여섯 단어의 빈도를 세고 적절한 가중치들을 곱하면 세 주제에 관한 3차원 주제 벡터를 획득.
- 3차원 벡터는 사람이 이해할 수 있는 형태로 시각화 가능. 그런 3차원 벡터들의 그래프를 그려보면 말뭉치 전체 또는 특정한 하나의 문서에 관한 통찰을 얻거나 공유 가능. 3차원 이하의 벡터들은 기계 학습 분류 문제를 고찰하기에도 좋으며, 벡터 공간을 평면(또는 초평면)으로 잘라서 공간 분할하는 알고리즘도 존재.
- 말뭉치의 문서들이 예제에 나온 것 보다 훨씬 많은 단어를 사용해도, 특정한 주제 벡터 모형은 여섯 단어의 빈도에만 영향을 받음. 시간과 인내심, 혹은 적당한 알고리즘을 통해 이 접근 방식을 더 많은 단어로 확장 가능.
- 문서들을 세 차원(주제)으로만 분리하면 된다는 조건이 성립하는 한, 단어의 수를 더 늘려도 이 3주제 접근 방식이 여전히 유효. 예시에서는 6차원을 3차원으로 압축했지만 필요하다면 더 많은 차원을 압축 가능.
- 그러나 위의 방식은 인간이 직접 직관과 상식에 기초, 문서들을 주제들로 분할하며 주제에 대한 각 단어의 점수(가중치)를 일일히 부여해야하는 주관적이고 노동량이 많은 의미 분석 접근 방식.
- 인간의 상식을 알고리즘의 형태로 정의하기란 어렵고, 이 접근 방식은 반복하기 어려움. 즉, 매번 다른 가중치를 선택할 가능성이 큼.
- 기계 학습 파이프라인에도 적합하지 않음. 주제와 단어의 수가 늘어나면 접근 방식을 적용하기가 어려워짐. 이 접근 방식은 규모 가변성이 나쁨.
- 일반적으로 NLP 응용 프로그램이 다루는 말뭉치는 수많은 문서로 이루어져 있으므로, 그 모든 문서의 의미를 정확하게 포착할 정도로 많은 수의 단어와 주제를 사람이 일일이 선택하고 조율하기란 사실상 불가능.
- 따라서 이러한 수작업을 자동화하는 것이 필요. 상식에 기초하지 않고도 주제 가중치를 선택하는 알고리즘이 필요.
- 가중합의 계산 방식을 생각해보면 각 가중합이 하나의 내적. 그리고 세 내적(가중합)은 행렬 곱셈에 해당.
- $3 \times n$ 가중 행렬에 한 문서의 가중 단어 빈도들로 이루어진 n차원 TF-IDF 벡터(여기서 n은 어휘 단어 수)를 곱한 결과는 문서의 주제를 말해 주는 하나의 $3 \times 1$ 주제 벡터. 수학의 관점에서 이는 한 벡터 공간에 있는 고차원 벡터(TF-IDF 벡터)를 그보다 낮은 차원의 다른 벡터 공간의 벡터(주제 벡터)로 '변환'하는 것에 해당. 
- 따라서 우리에게 필요한 알고리즘은 n개의 용어와 m개의 주제에 대한 행렬을 산출. 그리고 그 행렬에 한 문서의 가중 단어 빈도들로 이루어진 벡터를 곱하면 그 문서에 대한 주제 벡터가 됨.