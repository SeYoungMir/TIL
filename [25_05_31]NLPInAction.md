# 2. 더 깊은 학습: 신경망 적용
## 7. 단어 순서를 고려한 의미 분석: 합성곱 신경망
### 3. 합성곱 신경망
#### 4. 여백 채우기
- 좀 더 본격척인 처리 방법은 여백 채우기(padding)
- 여백 채우기는 입력 이미지의 가장자리에 여분의 자료를 덧붙이는 것을 말함. 그러면 입력 이미지와 같은 크기의 출력 이미지를 얻을 수 있을 뿐만 아니라, 원래의 가장자리 픽셀들이 이제는 '안쪽' 픽셀들이 되므로 앞에서 말한 과소표집 문제가 사라짐. 해당 케라스 설정을 padding='same'임. 이 접근 방식의 단점은 여분의 자료(원래의 입력과는 잠재적으로 무관한)가 출력에 영향을 미칠 수 있다는 점. 신경망이 가짜 자료에서 어떤 패턴을 찾아내는 것은 바람직하지 않음. 그러나 그런 악영향이 최소가 되도록 여백을 채우는 몇 가지 전략 고안. 다음 예제 참고.
- ```python
  from keras.models import Sequential
  from keras.layers import Conv1D

  model = sequential()
  model.add(Conv1D(filters= 16, kernel_size = 3, padding = 'same', activation = 'relu', strides = 1, input_shape = (100,300)))
  ```
- 구현 세부 사항은 나중에, 여기서 주목할 점은 합성곱 신경망의 정의와 구축에 관련된 여러 사항을 케라스가 처리해주는 덕분에 간결하고 추상적인 코드로 합성곱 신경망을 정의 가능하단는 점.
- 케라스가 사용하는 것 이외에도 여러 여백 값 선택 전략이 있음. 이를테면 전처리 과정에서 가장자리의 값들과 비슷한 값들을 선택하는 전략도 존재, 이는 NLP 응용 프로그램들에서 해가 될 수 있어 사용하지 않음.