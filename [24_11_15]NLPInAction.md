# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 1. 단어 빈도에서 주제 점수로
#### 5. LDA 분류기
- 차원 축소 기법과 분류 모형 중 가장 간단하고 빠른 것이 LDA. 그러니 이 기법은 그리 '화려하지'않기 때문에, NLP 관련 문헌에 자주 언급되지는 않음.
- 그렇지만 실제 응용에서는 최근 논문들로 발표된 좀 더 화려한 최신 알고리즘보다 더 정확한 결과를 낼 때도 많음. LDA 분류기(classiier)는 지도 학습 알고리즘에 속하므로, 미리 문서들에 분류명을 붙여 둔 훈련 자료가 필요. 또한 LDA에 필요한 훈련 견본의 수는 다른 알고리즘들보다 작음.
- 예제에서는 이진 분류를 위한 LDA를 직접 구현. scikit-learn에도 LDA 구현이 가능, 이번 예제의 모형 '훈련'과정은 간단한 세 단계 만으로 계산. 직접 구현해도 됨.
  - 1. 한 부류에 속하는 TF-IDF 벡터들의 평균 위치(무게중심)를 계산
  - 2. 다른 부류에 속하지 않는 TF-IDF 벡터들의 평균 위치(무게중심)를 계산
  - 3. 두 무게중심을 잇는 직선을 나타내는 벡터 계산
- LDA 모형의 '훈련'에 필요한 것은 이진 부류의 두 무게중심을 잇는 직선을 찾는 것. 이번 예제의 분류기는 주어진 단문 문자(SMS) 메시지가 스팸인지 아닌지를 분류. 이진 부류는 '스팸' 대 '비스팸'. LDA는 지도 학습에 속하므로 훈련용 문자(SMS)메시지들에 분류명(class label)을 붙여 두어야 함.
- 이러한 모형으로 추론(inference) 또는 예측을 수행하는 방법은 간단. 그냥 TF-IDF 벡터가 어느 부류의 무게 중심에 더 가까운지 보면 됨. 즉, 만일 TF-IDF 벡터가 스팸 부류 무게중심에 더 가깝다면 그 벡터에 해당하는 메시지는 스팸일 가능성이 큼.