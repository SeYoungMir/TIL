# 2. 더 깊은 학습: 신경망 적용
## 6. 단어 벡터를 이용한 추론: word2vec 활용
### 2. 단어 벡터
#### 7. word2vec 대 LSA
- word2vec과 GloVe를 앞에서 이야기한 LSA와 비교해보는 것도 유익.
- 앞에서 소개한 LSA의 주제-문서 벡터는 한 문서의 모든 단어에 대한 LSA 주제 벡터(주제-단어 벡터)들의 합. 이 주제-문서 벡터처럼 하나의 문서 전체의 의미 또는 주제를 담은 word2vec단어 벡터를 얻으려면 그냥 주어진 문서에 등장하는 모든 단어의 단어 벡터를 더하면 됨. 이는 doc2vec의 작동 방식과 거의 유사함.
- LSA의 주제-단어 행렬은 단어 수 $\times$ 주제 수 크기의 행렬로, 각 행은 LSA 단어 벡터(단어-주제 벡터)이고 각 열은 주제 벡터임. word2vec의 단어 벡터 처럼, 이 주제-단어 행렬의 각 행벡터는 한 단어의 의미를 200에서 300개 정도의 실수 수치들로 포착. 이들은 연관된 용어들을 찾거나 무관한 용어들을 찾는 데 도움이 됨. 앞에서 Glove를 소개할 때 언급했듯이, word2vec의 단어 벡터들을 역전파 댓힌 LSA에서 사용하는 것과 정확히 동일한 SVD 알고리즘으로 구하는 것이 가능. 그러나 word2vec이 이동 구간으로 문서를 훑는 과정에서 같은 단어가 이동 구간에 여러 번 포함되므로, word2vec은 같은 길이의 문장에서 다른 접근 방식보다 더 많은 정보를 추출할 수 있음. 예를 들어 이동 구간의 길이가 5이면 한 단어는 최대 5번 재사용됨.