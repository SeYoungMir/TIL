# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 4. 주성분 분석(PCA)
#### 4. 절단된 SVD를 이용한 문자 메시지 잠재 의미 분석
- PCA의 경우처럼 각 주제의 의미를 알려면 단어 가중치(주제 점수)들을 살펴봐야 함. 그렇지만 스팸 필터가 목적인 경우에는 각 주제의 구체적인 의미를 파악할 필요 없이 그 주제가 스팸과 관련된 것인지 아닌지만 파악해도 됨. 출력을 보면 훈련 자료에서 미리 스팸으로 분류된 메시지에는 해당 식별자(첫 열)에 느낌표(!)가 붙어 있음. 스팸 메시지들에서 점수가 높은 주제들은 스팸에 관한 주제일 가능성이 큼. 이런 식으로 수치들을 보고 스팸성 주제를 파악하기가 쉽지는 않지만 가능.
- 특히 컴퓨터라면 몇천 개의 훈련 견본들을 분석, 주제 공간에서 스팸성 주제들과 비스팸성 주제들을 어느 정도 잘 분리하는 기준들을 사람보다는 쉽게 찾아낼 수 있음.
#### 5. 스팸 분류에 대한 LSA의 정확도
- 이런 식으로 얻은 벡터 공간 모형이 스팸 분류에 얼마나 효과적인지 측정하는 한 가지 방법은 같은 부류(스팸 또는 비스팸)에 속하는 벡터들의 코사인 유사도를 보는 것. 이 방법이 유효한지 확인하기 위해, 처음 여섯 문자 메시지의 처음 여섯 주제 벡터들의 내적을 구해 봄. 이 방법이 유효하다면, 예를 들어 두 스팸 메시지 sms2와 sms5의 코사인 유사도가 크게 나오고, 햄 메시지 sms0과 스팸메시지 sms2의 코사인 유사도는 음수.
- ```python
  import numpy as np
  svd_topic_vectors = (svd_topic_vectors.T/np.linalg.norm(svd_topic_vectors,axis=1)).T
  svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)
  ```
- "sms0"열(대칭 행렬이므로 행도 마찬가지)을 따라가면서 다른 메시지들의 코사인 유사도를 살펴보면, 스팸 메시지들("sms2!","sms5!","sms8!","sms9!")과 "sms0"의 코사인 유사도는 모두 음수 따라서 "sms0"에 대한 주제 벡터는 이 스팸 메시지들에 대한 주제 벡터와 상당히 다름(서로 반대 방향을 보고 있음). 즉 이는 비스팸 메시지들이 스팸 메시지들과는 다른 내용을 말하고 있음을 뜻함.
- 같은 방식으로 "sms2!" 열을 따라가보면 다른 스팸 메시지들과의 코사인 유사도가 높음을 알 수 있음. 즉 스팸 메시지들은 비슷한 의미를 공유, 같은'주제'를 말함.
- 이상의 예는 의미 기반 검색의 작동 방식을 표현. 코사인 유사도를 이용해서 질의 벡터(질의문의 주제 벡터)를 문서 데이터베이스에 대한 주제 벡터들과 비교해서 질의 벡터와 가장 가까운(즉, 코사인 유사도가 가장 큰)주제 벡터를 탐색. 그 주제 벡터에 해당하는 문서가 바로 주어진 질의문과 가장 비슷한 의미를 담은 문서. '스팸성'은 문자 메시지 주제들에 혼합해 넣을 수 있는 '의미' 중 하나.