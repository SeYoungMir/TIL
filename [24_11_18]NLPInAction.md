# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 1. 단어 빈도에서 주제 점수로
#### 5. LDA 분류기
- 이전의 스팸 점수를 확률과 같이 0에서 1 사이의 수치로 변환 시 여러 용도로 활용하기 좋음.
- scikit-learn의 MinMaxScaler를 이용 시 쉽게 변환 가능.
- ```python
  from sklearn.preprocessing import MinMaxScaler
  sms['lda_score']= MinMaxScaler().fit_transform(spamminess_score.reshape(-1,1))
  sms['lda_predict']=(sms.lda_score > .5).astype(int)
  sms['spam lda_predict lda_score'split()].rount(2).head(6)
  ```
- 문턱값을 50%로 잡았을 때 처음 여섯 메시지가 정확하게 분류 훈련 집합의 나머지 메시지들에 대한 성과는 다음처럼 확인 가능
- ```python
  (1.-(sms.spam-sms.lad_predict).abs().sum()/len(sms)).round(3)
  ```
- 위와 같은 모형으로 97.7%의 메시지를 정확히 분류. 실제 응용에서 같은 정확도를 달성하기는 어려움. 이 정확도는 시험용 자료를 따로 분리하지 않고 훈련에 사용한 자료를 다시 시험에 사용했기 때문에, 분류기가 훈련한 자료를 얼마나 잘 기억하는지 말해줌.
- LDA는 매개 변수가 몇 개 되지 않는 아주 단순한 모형, 훈련용 문자 메시지들이 실제로 분류하고자 하는 문자 메시지들을 충분히 잘 대표하는 한, 실제문자 메시지들로도 잘 일반화. '교차 검증'을 수행하는 방법도 살펴보면 좋음
- 간단한 예제여도 의미 분석 접근 방식의 위력을 실감 가능. 단순 베이즈 분류 모형이나 로지스틱 회귀 모형과는 달리 의미 분석 모형은 개별 단어에 의존하지 않음. 의미 분석은 뜻이 비슷한(예시에서는 스팸에 해당)단어들을 모아서 함께 사용.
- 단, 훈련 집합이 어휘가 작으며 영어 사전에는 없는 단어들도 포함되어 있을 수 있음. 따라서 문자 메시지들이 비슷한 단어들을 사용하지 않는다면 분류 정확도가 그다지 높지 않음.
- 이 모형의 '혼동 행렬'(confusion matrix)이 어떤 모습인지 확인. 이 행렬은 스팸이 아닌데 스팸으로 잘못 분류된(거짓 양성) 메시지들과 스팸인데 스팸이 아니라고 분류된(거짓 음성) 메시지들에 관한 정보를 담고 있음.
- ```python
  from pugnlp.stats import Confusion
  Confusion(sms['spam lda_predict'.split()])
  ```
- 출력에 따르면 거짓 양성 결과는 64건, 거짓 음성 결과는 45건. 거짓 음성 결과보다 거짓 양성 결과가 많은 것이 문제라면 스팸 점수 문턱값 0.5를 변경해서 조율. 
- 다음 예제는 여러 개의 의미 점수로 이루어진 다차원 의미 벡터로 LSA를 수행하는 것. 다차원 의미 벡터는 단어들의 미묘하고 복합적인 의미를 좀 더 잘 반영.
- 다차원 LSA를 위해서는 특잇값 분해(SVD)가 필요. 다차원 LSA의 바탕인 SVD를 구체적으로 살펴보기 전에 LSA의 대안을 탐구.