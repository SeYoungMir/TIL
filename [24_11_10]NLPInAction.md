# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 1. 단어 빈도에서 주제 점수로
#### 3. TF-IDF 벡터 주제 벡터 변환 원리
- 한 문서에 대한 TF-IDF 벡터를 어떤 주제를 나타내는 주제 벡터로 변환한다고 상상. 
- 우선 해야 할 일은 각 단어가 그 주제에 기여하는 정도를 결정.
- 예를 들어 뉴욕 시의 센트럴 파크에 관한 문장들을 처리. 문장들의 주제로는 'petness'.'animalness','cityness' 같은 내용을 가정.
- 그렇다면 "cat",과 "dog" 같은 단어에는 "petness" 주제에 대한 점수(가중치)를 높게 부여해야 하며, "NYC"나 "apple"의 "petness" 주제 점수는 낮아야 함. 반대로 'cityness' 주제에 대해서는 "cat"과 "dog"보다 "NYC"의 점수가 높아야하고, 뉴욕시의 별명과 "apple"과의 연관성에 대해 어느 정도의 점수를 줘야 함.
- 다음은 각 단어의 주제 점수(가중치)들을 임의로 정해서 하나의 주제 모형(topic model)을 만들어보는 코드. 실제 NLP 파이프라인이라면 이런 가중치들을 사람이 직접 정하는 것이 아닌 기계 학습을 통해 구현
  - ```python
    >>> topic = {}
    >>> tfidf = dict(list(zip('cat dog apple lion NYC love'.split()),np.random.rand(6)))
    >>> topic['petness']=(.3*tfidf['cat']+ .3*tfidf['dog']......)

    ```
- 위 코드는 각 주제에 대해 각 단어의 TF-IDF 값에 그 단어가 주어진 주제와 얼마나 관련이 있는지를 나타내는 가중치를 곱하고 결과를 모두 합함. 주제와 무관한 (어떤 의미로는 주제와 "상반되는")단어는 가중치를 음수로 배정, 결과적으로 해당 단어는 주제 점수(가중합)을 감소하는 효과를 냄.
- 이 예제는 실제 알고리즘이 아니라 하나의 예시며, 실제 컴퓨터가 사람처럼 작동하기 위해 어떤 식으로 훈련을 시켜야 하는지 생각해보는 과정.
- 예제의 다음 단계는 어떤 주제와 단어가 연결, 그리고 그러한 연결의 가중치가 어느 정도인지를 수학적으로 계산하는 방법을 생각해 보는 것. 일단 세 가지 주제를 모형화하기로 했다면 그 주제들에 대한 각 단어의 가중치를 결정.
- 그러한 단어들의 가중 합은 해당 주제를 나타내는 "혼합색"에 해당. 예에서 주제 모형화 변환 법은 세 주제를 여섯 단어와 연관시키는 3 $\times$ 6  가중치(혼합 비율) 행렬로 정의. 이 행렬에 가상의 문서를 표현하는 6 $\times$ 1 TF-IDF 벡터를 곱하면 그 문서에 대한 3 $\times$ 1 주제 벡터가 산출.
