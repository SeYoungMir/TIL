# 2. 더 깊은 학습: 신경망 적용
## 5. 신경망 첫걸음: 퍼셉트론과 역전파
### 1. 신경망의 구성 요소
#### 3. 치우침 단위
##### 역전파
- 인공 신경망의 종류는 다양하지만, 어떤 것이든 다수의 뉴런이 특정한 방식으로 연결되어 있다는 점은 모두 같음.일반적으로는 뉴런들을 여러 개의 층(layer)으로 조직화, 꼭 그래야하는 것은 아님. 한 뉴런의 출력이 다른 뉴런의 입력이 되는 구조에서는 필연적으로 입력층과 출력층 사이에 숨겨진 뉴런들이 존재. 그런 뉴런들로 이루어진 층을 은닉층(hidden layer)이라고 부름
- 그리고 그 한 층의 뉴런들이 그 다음 층의 모든 뉴런과 연결된 신경망을 완전 연결(fully connected;또는 전결함) 신경망이라고 부름.신경망의 각 연결에는 하나의 가중치가 부여. 신경망이 많을 수록 연결도 많아지며 가중치도 이에 따라 많아짐.
- 신경망의 둘째 층의 뉴런들에 부여된 가중치는 원래의 입력 벡터가 아니라 그 이전 층(첫 층)의 출력에 적용됨에 주의. 이 때문에 첫 층이 전체 오차에 기여한 양을 계산하기가 까다로워짐. 첫 층의 가중치들은 오차에 직접 영향을 끼치는 것이 아니라 둘째 층의 입력에 영향을 미침으로써 간접적으로 영향을 미침. 이런 점을 고려해서 오차에 기초해서 가중치들을 갱신하는 역전파 알고리즘의 유도 과정과 수학적 세부 사항은 대단히 흥미롭지만 어려우므로, 간략하게나마 설명.