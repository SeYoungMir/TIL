# 1.NLP 기초.
## 4. 단어 빈도에서 의미 찾기: 의미 분석
### 5. 잠재 디리클레 할당(LDiA)
- LDiA는 도입부에서 했던 사고 실험과 비슷한 방식으로 의미 벡터 공간(주제 벡터들의 공간)을 산출. 사고 실험에서 특정 단어들이 같은 문서에 함께 등장하는 횟수에 기초, 단어들을 주제들에 직접 배정. 한 문서에 대한 각 단어의 주제 점수들을 이용, 문서의 주된 주제 파악.
- LDiA의 주제 모형도 이처럼 단어들을 주제에 배정, 주제들을 문서에 배정하는 접근 방식을 따름, 따라서 LSA보다 이해하기 쉬움.
- LDiA는 각 문서를 임의의 개수의 주제들의 혼합(일차 결합)으로 간주. 주제 개수는 LDiA 모형을 훈련하기 전에 개발자가 미리 정함.LDiA는 또한 각 주제를 단어 출현 횟수(용어 빈도)들의 분포로 표현할 수 있다고 가정. 더욱 중요하게는 LDiA에서는 한 주제가 어ㄸ너 한 문서의 실제 의미에 해당할 '확률'과 한 단어가 어ㄸ너 한 주제에 속할 '확률'이 디리클레 확률 분포(좀 더 정확하게는 사전(prior)확률 분포)를 따른다고 가정. 이 가정때문에 잠재 디리클레 할당이라는 이름이 붙음
#### 1. LDiA의 기초
- 디리클레 분포에 기초한 분석 방법은 2000년에 영국의 유전학자들이 유전자 서열에서 "집단 구조(population structure)를 추론하기 위해" 고안. NLP에서 이 접근 방식이 유명해진 것은 스탠퍼드 대학교의 데이비드 블레이와 앤드루 응, 마이클 조던이 쓴 2003년 논문 덕분. 파이썬 코드 몇 줄로 이 기법의 핵심을 소개. 간단한 예제를 통해 이 기법의 작동 방식을 직관적으로 이해하고 나면, 파이프라인에 어덯게 적용해야 할지(또는, 적어도 무엇을 더 공부해야 할지)짐작 가능.
- 블레이와 응은 앞의 사고 실험을 뒤집은 과정을 상상. 컴퓨터가 주사위를 던지는(난수 발생)것만으로 말뭉치의 문서들을 작성하는 방법을 고민. 단 , 컴퓨터가 다루는 것은 기본적으로 단어 모음들이므로, 단어들을 의미가 통하는 문장으로 연결해서 실제 문서를 작성하는 문제는 생략. 그냥 각 문서의 특정 BOW의 일부가 될 만한 단어들의 혼합에 대한 통계적 모형 생성.
- 그들의 논의에서 프로그램(문서 생성기)는 두 단어 중 하나를 선택하는 과정을 반복, 특정 문서에 대한 단어 혼합을 생성. 이 때 선택의 확률은 특정한 확률 분포를 따름.
- 어떤 확률 분포를 선택하느냐는 RPG 게임에서 캐릭터를 처음 설정할 때 캐릭터의 각 특성치를 몇 면 주사위를몇 개 던져서 계산하는 지 결정하는 것과 유사. LDiA도 이와 비슷하지만, 주사위의 면이 훨씬 많고, 주사위들도 훨씬 많으며 주사위 눈금들을 합산하는 규칙도 복잡, 이는 사람이 분석한 실제 문서들의 주제 및 단어 빈도들을 잘 반영하는 확률 분포를 적용하기 위해서.