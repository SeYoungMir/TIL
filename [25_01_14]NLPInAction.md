# 2. 더 깊은 학습: 신경망 적용
## 5. 신경망 첫걸음: 퍼셉트론과 역전파
### 1. 신경망의 구성 요소
#### 2. 디지털 퍼셉트론
- 앞에서 말한 생물학과 전류의 비유가 신경망의 이해에 도움이 되었길 바람. 그런 비유를 걷어버리고 퍼셉트론에 깔린 인공 신경망의 주요 개념을 탐색.
- 기본적으로, 신경망을 사용한다는 것은 어떤 자료 집합의 한 견본(example)을 신경망 알골리즘에 입력해서 알고리즘이 그 견본에 관해 어떤 값을 산출하는지 보는 것. 예를 들어 이진 분류의 경우 신경망 알고리즘은 주어진 견본이 특정 부류에 속하는지 아닌지를 뜻하는 '예' 또는 '아니오'에 해당하는 값 출력
- 이런 식으로 신경망을 활용하려면 먼저 하나의 견본이 어떤 특징(feature)들로 구성되는지 사람이 결정해야 함. 차차 알게 되겠지만, 적절한 특징들을 선택하는 것은 기계 학습 시스템의 개발에서 가장 어려운 과제 중 하나. 주택 가격 예측 같은 "보통의" 기계 학습 문제라면 평방미터당 가격, 최종 판매가, 우편번호 같은 것이 특징. 또는 ,Iris 자료 집합을 이용해서 어떤 붓꽃의 구체적인 품종을 예측하는 경우에는 꽃잎 길이, 꽃잎 너비, 꽃받침 길이, 꽃받침 너비 등이 특징.
- 로젠블랫의 실험에서는 이미지의 작은 영역의 빛의 세기가 특징. 그런 영역을 요즘 어법에 맞게 픽셀(pixel)이라고 부르기로 함. 하나의 광 수용기는 하나의 픽셀에 해당. 이 특징들 각각에 가중치(weight)를 부여해야 함. 그 가중치들의 근거가 무엇인지는 지금 결정할 필요가 없음 .그냥 뉴런에 입력 신호가 어느정도나 전달되는지를 결정하는 비율에 해당. 선형회귀에 익숙하다면 이 가중치들이 어디에서 비롯한 것인지 알 수 있음.
  - 일반적으로 개별 특징은 $x_i$처럼 소문자와 아래 첨자로 표기. 여기서 아래 첨자 $_i$는 이것이 $i$번째 특징임을 표시. 그리고 그런 특징들로 이루어진 하나의 견본은 $X$처럼 대문자로 표기. 견본은 특징들의 벡터
  - 각 특징에 부여된 가중치 역시 $w_i$처럼 소문장롸 아래 첨자로 표기. 여기서 $_i$는 이것이 $i$번째 특징 $x_i$의 가중치라는 의미. 가중치들을 통칭할 때는 $W$로 표기.
- 각 특징($x_i$)와 해당 가중치($w_i$)의 곱을 모두 합한 것이 퍼셉트론에 들어오는 입력값. 이는 곧 견본 벡터와 가중치 벡터의 일차결합.
- 뉴런(퍼셉트론)이 발화하려면 이 값이 특정 문턱값보다 커야함. 그러면 뉴런이 1을 출력하고, 그렇지 않으면 0을 출력.
- 이처럼 입력에 기초해서 뉴런의 출력을 결정하는 함수를 활성화 함수(activation function)라고 부름. 문턱값에 기초한 활성화 함수는 간단한 계단 함수(step function)에 해당.
