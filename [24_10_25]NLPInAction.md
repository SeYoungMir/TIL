# 1.NLP 기초.
## 3. TF-IDF 벡터
### 2. 벡터화
#### 1. 벡터 공간
- 앞의 내적 공식을 파이썬으로 표현한다면 다음과 같음.
  - ```python
    a.dot(b) == np.linalg.norm(a)*np.linalg.norm(b)/np.cos(theta)
    ```
- 다음은 위 관계식에 기초해 코사인 유사도를 계산하는 함수.
  - ```python
    >>> import math
    >>> def cosine_sim(vec1,vec2):
    ...     """두 문서 표현 벡터의 코사인 유사도 계산 함수"""
    ...     vec1=[val for val in vec1.values()]
    ...     vec2 = [val for val in vec2.values()]
    ...     dot_prod=0
    ...     for i, v in enumerate(vec1):
    ...         dot_prod+=v*vec2[i]
    ...     mag_1 = math.sqrt(sum([x**2 for x in vec1]))
    ...     mag_2 = math.sqrt(sum([x**2 for x in vec2]))
    ...      return dot_prod/(mag_1*mag_2)
    ```
- 이 함수는 우선 두 벡터의 내적을 구함. 두 벡터의 내적은 같은 위치의 두 성분을 곱해서 모두 더한 것과 같음. 함수는 for 루프로 성분별 곱들을 합산, 두 벡터의 내적을 계산. 그런 다음에는 이 내적을 두 벡터의 노름(길이)의 곱으로 나누어 정규화. 한 벡터의 노름은 벡터의 꼬리에서 머리까지의 유클리드 거리, 이는 곧 벡터의 각 성분의 제곱을 모두 합해서 제곱근을 취한 것.
- 이렇게 구한 정규화된 내적(normalized dot product)이 바로 앞에서 말한 -1에서 +1 범위의 코사인 유사도.
- 두 벡터의 내적은 더 짧은 벡터를 더 긴 벡터에 수직으로 투영해서 나온 벡터의 길이이기도 함. 두 벡터가 같은 방향을 가리킬수록 내적은 큰 양수가 되고, 반대 방향을 가리킬수록 큰 음수가 됨. 코사인 유사도는 그러한 내적을 두 벡터의 길이에 맞게 정규화. (이는 곧 두 벡터를 미리 길이가 1인 단위 벡터로 정규화한 후 내적을 구한 것과 동일)
- 코사인 유사도가 1이라는 것은 두 벡터가 모든 차원에서 완전히 같은 방향을 가리킨다는 뜻, 이는 길이(크기) 가 다를 수는 있지만 방향은 정확히 일치.
- NLP에서 두 문서 표현 벡터의 코사인 유사도가 1에 가깝다는 것은 두 벡터가 비슷한 단어들을 비슷한 빈도로 사용한다는 뜻. 따라서 벡터들의 코사인 유사도가 1에 가까운 두 문서는 비슷한 내용을 담고 있을 가능성이 큼.
- 코사인 유사도가 0이라는 것은 두 벡터에 공통점이 전혀 없다는 뜻. 기하학적으로 두 벡터는 직교. 두 벡터는 모든 차원에서 서로 수직
- NLP의 경우 두 문서에 공통으로 출현하는 단어가 하나도 없으면 해당 TF 벡터들의 코사인 유사도가 0이 됨. 그런 경우 두 문서는 서로 완전히 다른 단어들을 사용, 주제나 내용이 상당히다를 가능성이 큼. 그러나 같은 주제를 다른 단어들로 말하는 것이 불가능하지는 않다는 점에 주의
- 코사인 유사도가 -1이라는 것은 두 벡터가 완전히 반대 방향을 가리킨다는 뜻. 단순한 단어 횟수(용어 빈도)벡터는 이런 일이 일어나지 않음.심지어 정규화된 TF 벡터들로도 불가능. TF 벡터들은 벡터 공간의 같은 '사분명' 에 있으며, 코사인 유사도가 음수가 되려면 두 벡터중 하나가 다른 사분면에 있어야하는데, TF 벡터는 모든 성분(단어의 출현 횟수)이 반드시 0 아니면 양수이므로 그런 일이 생기지 않음.
- 이번 자연어 문서 표현 벡터들에서는 코사인 유사도가 음수인 경우가 생기지 않음.다음에 살펴볼 단어의 개념이나 문서의 주제를 표현하는 벡터들에서는 음수 코사인 유사도가 나올 수 있으며, 개념이나 주제의 경우 "상반되는" 개념이나 주제가 존재하기 때문.
  - 코사인 유사도의 계산 방식에서 한 가지 흥미로운 결과의 유도가 가능. 두 베터와 코사인 유사도가 -1인 또다른 벡터가 존재한다면 원래의 두 벡터는 아주 비슷함. 단 두 TF 벡터가 같은 방향이라고 해서 그 벡터들이 표현하는 두 문서가 같다는 뜻은 아님. 문서의 길이가 다를 수 있으며, 단어 순서들도 다를 수 있음.
